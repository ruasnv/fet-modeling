global_settings:
  matplotlib_style: 'default'
  figure_figsize: [10, 8]
  font_size: 8
  axes_labelsize: 10
  axes_titlesize: 12
  legend_fontsize: 8
  ignore_warnings: True
  debug_mode: False #Set to "true" to enable DEBUG prints

paths:
  raw_data_path: 'data/nmoshv.csv'
  processed_data_dir: 'data/processed'
  trained_model_dir: 'models'
  report_output_dir: 'results'
  eda_output_dir: 'results/eda'
  loss_output_dir: 'results/losses'
  aug_data_dir: 'data/augmented'

filtering:
  id_greater_than_zero: True # Filter out data points where 'id' <= 0
  vds_greater_than_zero: True # Filter out data points where 'vd' <= 0
  temperature_filter: 27 # temperature (C) to filter for

feature_engineering:
  input_features: ['vg', 'vd', 'vb', 'w', 'l', 'wOverL'] # Base features to be used as model inputs
  target_feature: 'log_Id' # Name of the target feature

normalization:
  method: "StandardScaler" # Scaling method for features and target
  log_transform_id: True # Apply log10 transformation to 'id' to create 'log_Id'

region_classification:
  stratify_column: 'operating_region' # Column to use for stratified splitting
  method: "vth_based" # Method for classifying operating regions: 'vth_based'

# Parameters for calculate_vth helper function (body effect formula)
vth_params:
  vth0: 0.7 # Zero-bias threshold voltage (Vth at Vsb=0)
  gamma: 0.5 # Body effect coefficient
  phi_f: 0.4 # Fermi potential

data_split:
  cv_final_test_split_ratio: 0.15 # Ratio of data to reserve for the final test set
  num_folds: 10 # Number of folds for K-fold cross-validation
  random_state: 42 # Seed for reproducibility of data splits

model_params:
  input_dim: 6 # Number of input features (Vgs, Vds, Vbs, W, L)
  final_model_filename: 'final_model.pth'

training_params:
  num_epochs: 100
  batch_size: 64
  learning_rate: 0.001
  criterion: "MSELoss" # Loss function to use
  optimizer: "Adam" # Optimizer to use

run_flags:
  run_cross_validation: True # Whether to execute the cross-validation step
  skip_training_if_exists: True # If a model file exists, load it instead of retraining
  skip_plots_if_exists: True # If plot directory exists and is not empty, skip generating plots

plot_cases:
  - device_size: [1.0, 0.5]
    vbs_val: -1.0
    plot_type: "Id_Vgs_fixed_Vds"
    fixed_vds_vals: [0.1, 0.5, 1.0, 3.0]
  - device_size: [5.0, 0.1]
    vbs_val: 0.0
    plot_type: "Id_Vds_fixed_Vgs"
    fixed_vgs_vals: [0.5, 1.0, 2.0, 3.0]

gan_params:
  latent_dim: 100 # Dimension of the noise vector for the Generator
  num_gan_epochs: 2000 # Number of epochs to train each GAN. GANs often need many epochs, yet it is kept small bc of the lack of resources
  gan_batch_size: 128  # Batch size for GAN training
  generator_learning_rate: 0.0002
  discriminator_learning_rate: 0.0002
  additional_majority_samples: 200

